## 什么是高并发

高并发（High Concurrency）是指通过设计保证系统能够同时并行处理很多请求。

常用指标有：
- QPS，每秒响应请求数
- TPS，每秒响应事务数
- RT，响应时间，系统对请求做出响应的时间
- Concurrency，并发数，系统同时能处理的请求数量
- 吞吐量：单位时间内处理的请求数量

## 提高并发的思路

- 降低 RT
- 提高 Concurrency

## 如何降低 RT

- 升级服务器和数据库硬件配置，最简单粗暴且有效的手段，但是硬件能带来的提升是有上限的
- 服务端引入缓存，缓存分为本地缓存和分布式缓存，可显著降低查询接口的响应时间
- 购买 CDN 服务，将图片、html、css、js等静态资源上传到 CDN，可显著降低用户打开页面的响应时间
- 业务优化，比如流程拆分，将实时性要求低的流程写入消息队列进行异步处理，将互相独立的流程并行处理；数据预加载；避免热点数据；索引优化；JVM 优化等

## 如何提高 Concurrency

- 使用反向代理 Nginx，可以大大的提高服务的并发数，一般可以达到 10w 并发数，此时单机数据库会出现瓶颈
- 数据库读写分离，数据库使用主从模式，对一致性要求低的查询请求可以走从库，分担主库压力
- 数据库分库分表，把不同业务的数据放到不同的数据库中，如果单表数据量过大，可以进行分表存储。分库分表可以显著提升数据库查询的效率
- 使用负载均技术 LVS/F5，此时 Nginx 已经成为瓶颈，多加一层 Nginx 会影响 RT，所以一般会使用更高效的负载均衡软件 LVS 或者硬件 F5，此时并发数可以上升到几十万
- 使用 DNS 负载均衡，可以在域名下面绑定多个虚拟IP，每个虚拟 IP 指向一个机房，此时并发数已经来到百万、千万甚至亿的级别，服务入口的并发数将不在是瓶颈。

## 架构图

世上没有万能的架构，需要根据实际情况进行权衡。
![image.png](https://raw.githubusercontent.com/neilzhang/blog-images/main/posts/20220806/20220806113042.png)

